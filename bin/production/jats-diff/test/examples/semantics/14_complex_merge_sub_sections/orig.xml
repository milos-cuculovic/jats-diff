<?xml version="1.0" encoding="UTF-8"?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="review-article" dtd-version="1.1" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">remotesensing</journal-id>
      <journal-title-group>
        <journal-title>Remote Sensing</journal-title>
        <abbrev-journal-title abbrev-type="publisher">Remote Sens.</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="pubmed">Remote Sensing</abbrev-journal-title>
      </journal-title-group>
      <issn pub-type="epub">2072-4292</issn>
      <publisher>
        <publisher-name>MDPI</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">remotesensing-10-006415</article-id>
      <article-categories>
        <subj-group>
          <subject>
            <p>Review</p>
            <p>Additional Review data</p>
            <p>other</p>
          </subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>
          <p>On the Use of Unmanned Aerial Systems for Environmental Monitoring</p>
        </article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0225-144X</contrib-id>
          <name>
            <surname>Manfreda Oscaro</surname>
            <given-names>Salvatore</given-names>
          </name>
          <xref rid="af1-remotesensing-10-00641" ref-type="aff">1</xref>
          <xref rid="c1-remotesensing-10-00641" ref-type="corresp">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1279-5272</contrib-id>
          <name>
            <surname>McCabe</surname>
            <given-names>Matthew F.</given-names>
          </name>
          <xref rid="af2-remotesensing-10-00641" ref-type="aff">2</xref>
        </contrib>
      </contrib-group>
      <aff id="af1-remotesensing-10-00641"><label>1</label>Dipartimento delle Culture Europee e del Mediterraneo: Architettura, Ambiente, Patrimoni Culturali (DiCEM), Universita degli Studi della Basilicata, 75100 Matera, Italy</aff>
      <aff id="af2-remotesensing-10-00641"><label>2</label>Water Desalination and Reuse Center, King Abdullah University of Science and Technology, 23955 Thuwal, Saudi Arabia</aff>
      <author-notes>
        <corresp id="c1-remotesensing-10-00641"><label>*</label>Correspondence: <email>salvatore.Manfreda@unibas.it</email></corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>20</day>
        <month>04</month>
        <year>2018</year>
      </pub-date>
      <pub-date pub-type="collection">
        <month>04</month>
        <year>2018</year>
      </pub-date>
      <volume>10</volume>
      <issue>4</issue>
      <elocation-id>641</elocation-id>
      <history>
        <date date-type="received">
          <day>12</day>
          <month>03</month>
          <year>2018</year>
        </date>
        <date date-type="accepted">
          <day>17</day>
          <month>04</month>
          <year>2018</year>
        </date>
      </history>
      <permissions>
        <p>permission 1</p>
        <p>permission additional</p>
        <copyright-statement>&#xA9; 2018 by the authors.</copyright-statement>
        <copyright-year>2018</copyright-year>
        <license license-type="open-access">
          <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Environmental <b>monitoring</b> plays a central role in diagnosing climate and management hello impacts on natural and agricultural systems; enhancing the understanding of hydrological processes; optimizing the allocation and distribution of water resources; and assessing, forecasting, and even preventing natural disasters. Nowadays, most monitoring and data collection systems are based upon a combination of ground-based measurements, manned airborne sensors, and satellite observations. These data are utilized in describing both small- and large-scale processes, but have spatiotemporal constraints inherent to each respective collection system. Bridging the unique spatial and temporal divides that limit current monitoring platforms is key to improving our understanding of environmental systems. In this context, Unmanned Aerial Systems (UAS) have considerable potential to radically improve environmental monitoring. UAS-mounted sensors offer an extraordinary opportunity to bridge the existing gap between field observations and traditional air- and space-borne remote sensing, by providing high spatial detail over relatively large areas in a cost-effective way and an entirely new capacity for enhanced temporal retrieval. As well as showcasing recent advances in the field, there is also a need to identify and understand the potential limitations of UAS technology. For these platforms to reach their monitoring potential, a wide spectrum of unresolved issues and application-specific challenges require focused community attention. Indeed, to leverage the full potential of UAS-based approaches, sensing technologies, measurement protocols, postprocessing techniques, retrieval <i>algorithms</i>, and evaluation techniques need to be harmonized. The aim of this paper is to provide an overview of the existing research and applications of UAS in natural and agricultural ecosystem monitoring in order to identify future directions, applications, developments, and challenges.</p>
        <p>this is additional string that check style changes, this is additional string italic</p>
        <p>this is item move text in one node text for move end</p>
        <p>delete one node <b>alo</b></p>
      </abstract>
      <kwd-group>
        <kwd>UAS</kwd>
        <kwd>remote sensing</kwd>
        <kwd>environmental monitoring</kwd>
        <kwd>precision agriculture</kwd>
        <kwd>vegetation indices</kwd>
        <kwd>soil moisture</kwd>
        <kwd>river monitoring</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec1-remotesensing-10-00641" sec-type="intro">
      <title>1. Introduction</title>
      <p>Despite the recent and rapid increase in the number and range of Earth observing satellites [<xref ref-type="bibr" rid="B1-remotesensing-10-00641">1</xref>,<xref ref-type="bibr" rid="B2-remotesensing-10-00641">2</xref>,<xref ref-type="bibr" rid="B3-remotesensing-10-00641">3</xref>], the temporal resolution and availability of current very high spatial resolution satellite sensors (less than 10 m) are generally not sufficient nor flexible enough for many quantitative remote sensing applications, and they are thus of limited use in detecting and monitoring the dynamics of surficial environmental processes. Recent advances in Earth observation (i.e., EO) are opening new opportunities for environmental monitoring at finer scales [<xref ref-type="bibr" rid="B4-remotesensing-10-00641">4</xref>]. For instance, CubeSat platforms represent a promising satellite technology, operating predominantly in the visible to near-infrared portion of the electromagnetic spectrum, and provide high spatial and temporal resolution [<xref ref-type="bibr" rid="B5-remotesensing-10-00641">5</xref>]. Nevertheless, most of these satellites are operated by commercial organizations; hence, if short revisit times are required (i.e., for high-frequency monitoring), the cost of image acquisition can become a limiting factor. While manned airborne platforms can, in principle, provide both high spatial resolution and rapid revisit times, in practice, their use is routinely limited by operational complexity, safety, logistics, and cost. Their use becomes feasible only over medium-sized areas and remains largely within the domain of commercial operators. Recent advances in Unmanned Aerial Systems (UAS) technology have created an alternative monitoring platform that provides an opportunity to capture the spatial, spectral, and temporal requirements across a range of applications with relatively small investment. They offer high versatility, adaptability, and flexibility compared with manned airborne systems or satellites, and have the potential to be rapidly and repeatedly deployed for high spatial and temporal resolution data [<xref ref-type="bibr" rid="B6-remotesensing-10-00641">6</xref>].</p>
      <p>While UAS systems cannot compete with satellite imagery in terms of spatial coverage, they provide unprecedented spatial and temporal resolutions unmatched by satellite alternatives. Furthermore, they do so at a fraction of the satellite acquisition cost if the area of interest has relatively small extent. For example, a newly tasked high-resolution natural color image (50 cm/pixel) from a satellite (e.g., GeoEye-1) can cost up to 3000 USD. On the other hand, the initial outlay to acquire a single UAS with a natural color camera can be less than 1000 USD (see <xref ref-type="app" rid="app1-remotesensing-10-00641">Appendix A</xref>), with this delivering a dataset of high spatial resolution (several cm/pixel). Of course, the additional benefit of the UAS platform is that the temporal resolution is limited only by the number of flights (and power supply/battery capacity), so any cost equivalence is quickly overcome due to repeatability. The costs for acquiring UAS imagery are usually derived from the initial investment, the processing software, data storage, and associated (and ongoing) fieldwork expenses. However, after the initial investment, datasets can be delivered more often and at a higher resolution than by any other EO system.</p>
      <p>Matese et al. [<xref ref-type="bibr" rid="B7-remotesensing-10-00641">7</xref>] provided an intercomparison of the acquisition and processing costs of three different platforms (UAS, Aircraft, and Satellite). Their cost model parametrization allows the derivation of the relative cost for the different configurations, showing that UAS is the most cost-effective solution for fields of an extent equal to or less than 20 ha. Their quantitative analyses showed that the approximate total cost of a UAS-derived Normalized Difference Vegetation Index (NDVI) map over a 5 ha field is equal to 400 &#x20AC;/ha, while satellite products may cost about 30% more.</p>
    </sec>
    <sec id="sec2-remotesensing-10-00641">
      <title>2. Data Collection, Processing, and Limitations</title>
      <p>While offering an unprecedented platform to advance spatiotemporal insights across the Earth and environmental sciences, UAS are not without their own operational, processing, and retrieval problems. These range from image blur due to the forward motion of the platform [<xref ref-type="bibr" rid="B34-remotesensing-10-00641">34</xref>], resolution impacts due to variable flying height, orthorectification issues and geometric distortion associated with inadequate image overlap [<xref ref-type="bibr" rid="B35-remotesensing-10-00641">35</xref>], and the spectral effects induced by variable illumination during flight. These and other factors can all affect the subsequent quality of any orthorectified image and, subsequently, the derived products. These are well described in a recent review paper by Whitehead and Hugenholtz [<xref ref-type="bibr" rid="B13-remotesensing-10-00641">13</xref>]. As such, it is essential to consider best practice in the context of (a) mission and flight planning; (b) preflight camera/sensor configuration; (c) in-flight data collection; (d) ground control/ radiometric calibration and correction; (e) geometric and atmospheric corrections; (f) orthorectification and image mosaicking; and (g) extracting relevant products/metrics for remote sensing application. Items (a) and (b) are preflight tasks, (c) and (d) are conducted in the field at the time of survey, and (e)&#x2013;(g) are postsurvey tasks. Together, these aspects are crucial to data acquisition and postprocessing, which deliver the necessary starting point for subsequent application-specific analysis. However, despite the existence of well-established workflows in photogrammetry, manned aircraft, and satellite-based remote sensing to address such fundamental aspects, UAS systems introduce various additional complexities, which to date have not been thoroughly addressed. Consequently, best practice workflows for producing high-quality remote sensing products from UAS are still lacking, and further studies that focus on validating UAS-collected measurements with robust processing methods are important for improving the final quality of the processed data [<xref ref-type="bibr" rid="B36-remotesensing-10-00641">36</xref>,<xref ref-type="bibr" rid="B37-remotesensing-10-00641">37</xref>].</p>
      <sec id="sec2dot1-remotesensing-10-00641">
        <title>2.1. Preflight Planning</title>
        <p>Flight or mission planning is the first essential step for UAS data acquisition and has a profound impact on the data acquired and the processing workflow. Similar to other remote sensing approaches, a host of parameters must be considered before the actual flight, such as platform specifications, the extent of the study site (area-of-interest), ground sampling distance, payload characteristics, topography of the study site, goals of the study, meteorological forecasts, and local flight regulations. UAS have additional aspects that require further consideration, including the skill level of the pilot, platform characteristics, and actual environmental flight conditions&#x2014;all of which affect the data characteristics and subsequent phases of processing.</p>
        <p>Due to the proliferation of low-cost, off-the-shelf digital cameras, photogrammetry has been the primary implementation of UAS. James and Robson [<xref ref-type="bibr" rid="B38-remotesensing-10-00641">38</xref>] highlighted how unresolved elements of the camera model (lens distortion) can propagate as errors in UAS-DEMs (derived digital elevation models), and how this can be addressed by incorporating oblique images. Other studies have highlighted the importance of flight line configurations [<xref ref-type="bibr" rid="B39-remotesensing-10-00641">39</xref>], as well as minimizing image blur [<xref ref-type="bibr" rid="B34-remotesensing-10-00641">34</xref>]. There is a need to consolidate this evidence to develop best practice guidance for optimizing UAS SfM (structure-from-motion) measurement quality, whilst maintaining ease of use and accessibility.</p>
        <p>Accurate absolute orientation (georeferencing) is an important element for UAS surveys, and is fundamental for any multitemporal monitoring or comparison to other datasets. This task is often referred to as registration, and is conventionally dependent on establishing ground control points (GCPs) which are fixed by a higher-order control method (usually Global Navigation Satellite System&#x2014;GNSS or Global Positioning System). A number of studies have examined the effect of GCP networks (number and distribution) in UAS surveys, showing that significant errors are expected in SfM-based products where GCPs are not adopted [<xref ref-type="bibr" rid="B39-remotesensing-10-00641">39</xref>,<xref ref-type="bibr" rid="B40-remotesensing-10-00641">40</xref>]. Nevertheless, systematic DEM error can be significantly reduced by including properly defined GCPs [<xref ref-type="bibr" rid="B41-remotesensing-10-00641">41</xref>] or incorporating oblique images in the absence of GCP [<xref ref-type="bibr" rid="B38-remotesensing-10-00641">38</xref>].</p>
        <p>Best practice can also be drawn from manned aerial photogrammetry. Direct georeferencing is standard practice in aerial photogrammetry, where the position and orientation of the platform are precisely determined using on-board survey-grade differential GNSS and inertial measurement unit (IMU) data combined through an inertial navigation system (INS) [<xref ref-type="bibr" rid="B42-remotesensing-10-00641">42</xref>]. This allows the camera station (exposure) position and orientation to be derived directly, thus eliminating or minimizing the need for ground control points. Therefore, as discussed by Colomina and Molina [<xref ref-type="bibr" rid="B35-remotesensing-10-00641">35</xref>], there is an increasing drive towards achieving centimeter-level direct georeferencing for UAS using alternative GNSS/IMU configurations, precise point positioning (PPP), and dual-frequency GNSS.</p>
      </sec>
    </sec>
    <sec id="sec3-remotesensing-10-00641">
      <title>3. Monitoring Agricultural and Natural Ecosystems</title>
      <p>Natural and agricultural ecosystems are influenced by climatic forcing, physical characteristics, and management practices that are highly variable in both time and space. Moreover, vegetation state changes can often occur within a short period of time [<xref ref-type="bibr" rid="B60-remotesensing-10-00641">60</xref>,<xref ref-type="bibr" rid="B61-remotesensing-10-00641">61</xref>] due to unfavorable growing conditions or climatic extremes (e.g., heat waves, heavy storms, etc.). Therefore, in order to capture such features, monitoring systems need to provide accurate information over large areas with a high revisit frequency [<xref ref-type="bibr" rid="B62-remotesensing-10-00641">62</xref>]. UAS platforms provide one such technology that is enabling new horizons in vegetation monitoring. For instance, the high resolution of UAS imagery has led to a significant increase in the overall accuracy in species-level vegetation classification, monitoring vegetation status, weed infestations, estimating biomass, predicting yields, detecting crop water stress and/senescent leaves, reviewing herbicide applications, and pest control.</p>
      <sec id="sec3dot1-remotesensing-10-00641">
        <title>3.1. Vegetation Monitoring and Precision Agriculture</title>
        <p>Precision agriculture [<xref ref-type="bibr" rid="B63-remotesensing-10-00641">63</xref>] has been the most common environmental monitoring application of UAS. High-spatial-resolution UAS imagery enables much earlier and more cost-effective detection, diagnosis, and corrective action of agricultural management problems compared to low-resolution satellite imagery. Therefore, UAS may provide the required information to address the needs of farmers or other users at the field scale, enabling them to make better management decisions with minimal costs and environmental impact [<xref ref-type="bibr" rid="B64-remotesensing-10-00641">64</xref>,<xref ref-type="bibr" rid="B65-remotesensing-10-00641">65</xref>,<xref ref-type="bibr" rid="B66-remotesensing-10-00641">66</xref>].</p>
      </sec>
      <sec id="sec3dot2-remotesensing-10-00641">
        <title>3.2. Test sec</title>
        <p>Vegetation state can be evaluated and quantified through different vegetation indices from images acquired in the visible, red edge, and near-infrared spectral bands. Depending on their formulation, these can display a strong correlation with soil coverage and Leaf and Green Area Index (LAI and GAI), Crop Nitrogen Uptake (QN), chlorophyll content, water stress detection, canopy structure, photosynthesis, yield, and/or growing conditions [<xref ref-type="bibr" rid="B67-remotesensing-10-00641">67</xref>,<xref ref-type="bibr" rid="B68-remotesensing-10-00641">68</xref>,<xref ref-type="bibr" rid="B69-remotesensing-10-00641">69</xref>]. As such, these vegetation indices may be exploited to monitor biophysical parameters.</p>
        <p>Among the many available vegetation indices, the Normalized Difference Vegetation Index (NDVI) is one that is most widely used [<xref ref-type="bibr" rid="B70-remotesensing-10-00641">70</xref>,<xref ref-type="bibr" rid="B71-remotesensing-10-00641">71</xref>,<xref ref-type="bibr" rid="B72-remotesensing-10-00641">72</xref>]. UAS-NDVI maps can be at least comparable to those obtained from satellite visible observations and become highly relevant for a timely assessment of crop health status, with capacity to provide immediate feedback to the farmer. NDVI surveys performed with UAS, aircraft, and satellite demonstrate that low-resolution images generally fail in representing intrafield variability and patterns in fields characterized by small vegetation gradients and high vegetation patchiness [<xref ref-type="bibr" rid="B7-remotesensing-10-00641">7</xref>]. Moreover, UAS-derived NDVIs have shown better agreement with ground-based NDVI observations compared to satellite-derived NDVIs in several crop and natural vegetation types [<xref ref-type="bibr" rid="B73-remotesensing-10-00641">73</xref>,<xref ref-type="bibr" rid="B74-remotesensing-10-00641">74</xref>,<xref ref-type="bibr" rid="B75-remotesensing-10-00641">75</xref>]. As an example of the achievable resolution that can be obtained from UAVs, relative to some available high-resolution commercial satellite sensors, <xref ref-type="fig" rid="remotesensing-10-00641-f003">Figure 3</xref> shows a multi-sensor sequence of imagery collected over a date palm plantation in Saudi Arabia. The observed differences between vegetation patterns and resolvable resolution observed by UAS (compared to available satellite platforms) are clearly identified. The relative advantages of UAS in providing a level of detail that is comparable to field observations (or in deriving NDVI or other related vegetation indices for more in depth assessment) is illustrated by its capability of capturing both within and between canopy behavior.</p>
        <p>In the last decade, particular attention has been given to the monitoring of vineyards because of their high economic value. Johnson et al. [<xref ref-type="bibr" rid="B76-remotesensing-10-00641">76</xref>] proposed one of the first applications where different sensors were used for determining measures related to chlorophyll function and photosynthetic activity, LAI, and plant health status (among other variables) to mapping vigor differences within fields. More recently, Zarco-Tejada et al. [<xref ref-type="bibr" rid="B52-remotesensing-10-00641">52</xref>,<xref ref-type="bibr" rid="B77-remotesensing-10-00641">77</xref>,<xref ref-type="bibr" rid="B78-remotesensing-10-00641">78</xref>,<xref ref-type="bibr" rid="B79-remotesensing-10-00641">79</xref>,<xref ref-type="bibr" rid="B80-remotesensing-10-00641">80</xref>] demonstrated the potential for monitoring specific variables such as crop water stress index, photosynthetic activity, and carotenoid content in vineyards using multispectral, hyperspectral, and thermal cameras.</p>
        <p>Based upon author experiences, farmers have expressed particular interest in monitoring crop conditions for the quantification of water demand, nitrogen status, or infestation treatments. Several of the variables or indices described above may be used for rapid detection of crop pest outbreaks or for mapping the status of crops. Likewise, monitoring soil water content is critical for determining efficient irrigation scheduling. The topsoil moisture content can be derived using RGB, NIR, and thermal bands [<xref ref-type="bibr" rid="B81-remotesensing-10-00641">81</xref>]. The effective amount of water stored in the subsurface can be obtained by exploiting mathematical relationships between surface measurements and the root zone soil moisture, such as the Soil Moisture Analytical Relationship (SMAR) [<xref ref-type="bibr" rid="B82-remotesensing-10-00641">82</xref>,<xref ref-type="bibr" rid="B83-remotesensing-10-00641">83</xref>].</p>
        <p>As a further example, Sullivan et al. [<xref ref-type="bibr" rid="B84-remotesensing-10-00641">84</xref>] observed that the thermal infrared (TIR) emittance was highly sensitive to canopy state and can be used for monitoring soil water content, stomatal conductance, and canopy cover. TIR has similarly been used for the monitoring and estimation of soil surface characteristics such as microrelief and rill morphology [<xref ref-type="bibr" rid="B85-remotesensing-10-00641">85</xref>], soil water repellency [<xref ref-type="bibr" rid="B86-remotesensing-10-00641">86</xref>], soil surface macropores [<xref ref-type="bibr" rid="B87-remotesensing-10-00641">87</xref>], skin surface soil permeability [<xref ref-type="bibr" rid="B88-remotesensing-10-00641">88</xref>], and overland and rill flow velocities by using thermal tracers [<xref ref-type="bibr" rid="B89-remotesensing-10-00641">89</xref>,<xref ref-type="bibr" rid="B90-remotesensing-10-00641">90</xref>].</p>
        <p>More specifically, the TIR emittance displays a negative correlation with stomatal conductance and canopy closure, indicating increasing canopy stress as stomatal conductance and canopy closure decreased. The crop water stress index (CWSI) [<xref ref-type="bibr" rid="B91-remotesensing-10-00641">91</xref>,<xref ref-type="bibr" rid="B92-remotesensing-10-00641">92</xref>] calculated from leaf water potential can be used to determine the required frequency, timing, and duration of watering. In this regard, the CWSI, derived with a UAS equipped with a thermal camera, is frequently adopted to quantify the physiological status of plants, and, more specifically, leaf water potential in experimental vineyards or orchards [<xref ref-type="bibr" rid="B52-remotesensing-10-00641">52</xref>,<xref ref-type="bibr" rid="B80-remotesensing-10-00641">80</xref>,<xref ref-type="bibr" rid="B93-remotesensing-10-00641">93</xref>,<xref ref-type="bibr" rid="B94-remotesensing-10-00641">94</xref>,<xref ref-type="bibr" rid="B95-remotesensing-10-00641">95</xref>,<xref ref-type="bibr" rid="B96-remotesensing-10-00641">96</xref>]. The derived CWSI maps can serve as important inputs for precision irrigation. Time series of thermal images can also be used to determine the variation in water status [<xref ref-type="bibr" rid="B97-remotesensing-10-00641">97</xref>].</p>
        <p>Using VIS&#x2013;NIR (400&#x2013;1000 nm) hyperspectral and multispectral analyses of simulated data has shown that soil attributes can be extracted from these spectral regions, particularly those most commonly used by the current UAS platforms [<xref ref-type="bibr" rid="B98-remotesensing-10-00641">98</xref>,<xref ref-type="bibr" rid="B99-remotesensing-10-00641">99</xref>,<xref ref-type="bibr" rid="B100-remotesensing-10-00641">100</xref>]. These studies demonstrated that the VIS-NIR spectral region alone can open up new frontiers in soil mapping (as well as soil moisture content retrieval) using on-board multi- and hyperspectral UAS sensors without using heavyweight sensors operating in the SWIR (1&#x2013;2.5 &#x3BC;m) region. Aldana-Jague et al. [<xref ref-type="bibr" rid="B32-remotesensing-10-00641">32</xref>] mapped soil surface organic carbon content (&lt;0.5 cm) at 12 cm resolution exploiting six bands between 450 and 1050 nm acquired by low-altitude multispectral imagers. D&#x2019;Oleire-Oltmanns et al. [<xref ref-type="bibr" rid="B30-remotesensing-10-00641">30</xref>] showed the applicability of UAS for measuring, mapping, and monitoring soil erosion at 5 cm resolution with an accuracy between 0.90 and 2.7 cm in the horizontal and 0.70 cm in the vertical directions. Detailed information about soil erosion can enhance proper soil management at the plot scale [<xref ref-type="bibr" rid="B31-remotesensing-10-00641">31</xref>].</p>
        <p>Such tools were further explored by Zhu et al. [<xref ref-type="bibr" rid="B22-remotesensing-10-00641">22</xref>], who investigated the ability to quantify the differences in soil nitrogen application rates using digital images taken from a UAS compared with ground-based hyperspectral reflectance and chlorophyll content data. They suggested that aerial photography from a UAS has the potential to provide input in support of crop decision-making processes, minimizing field sampling efforts, saving both time and money, and enabling accurate assessment of different nitrogen application rates. Therefore, such information may serve as input to other agricultural systems, such as tractors or specific UAS, that optimize fertilizer management.</p>
        <p>UAS can also improve agronomical practices. Costa et al. [<xref ref-type="bibr" rid="B101-remotesensing-10-00641">101</xref>] described an architecture that can be employed to implement a control loop for agricultural applications where UAS are responsible for spraying chemicals on crops. Application of chemicals is controlled by the feedback obtained from a wireless sensor network (WSN) deployed on the crop field. They evaluated an algorithm to adjust the UAS route under changes in wind (intensity and direction) to minimize the waste of pesticides. Pe&#xF1;a et al. [<xref ref-type="bibr" rid="B102-remotesensing-10-00641">102</xref>,<xref ref-type="bibr" rid="B103-remotesensing-10-00641">103</xref>] explored the optimization of herbicide applications in weed&#x2013;crop systems using a series of UAS multispectral images. The authors computed multiple data, which permitted both calculation of herbicide requirements and estimation of the overall cost of weed management operations in advance. They showed that the ability to discriminate weeds was significantly affected by the imagery spectra (type of camera) used as well as the spatial (flight altitude) and temporal (the date of the study) resolutions.</p>
        <p>Among these technical advantages and constraints, the importance of the limitation of operational rules in using UAS in several countries needs to be highlighted. As an example, Jeunnette and Hart [<xref ref-type="bibr" rid="B24-remotesensing-10-00641">24</xref>] developed a parametric numerical model to compare aerial platform options (UAS vs airborne) to support agriculture in developing countries characterized by highly fragmented fields, but manned systems are still more competitive from an operational and cost/efficiency point of view because of the present limitations in altitude, distance, and speed of UAS. In particular, UAS become cost-competitive when they are allowed to fly higher than 300 m AGL (above ground level), while current limits are set around 120&#x2013;150 m. This is a critical limitation for the use of UAS along with the fact that flights should be within visible line of sight (VLOS) in many jurisdictions.</p>
        <p>All the applications described highlight the potential use of UAS in developing advanced tools for precision agriculture applications and for vegetation monitoring in general. With time, both technological advances and legislation will evolve and likely converge, further advancing the efficient use of such technologies.</p>
      </sec>
    </sec>
  </body>
</article>
